## モデルフリー

モデルフリーな状況では、状態遷移確率が未知であるため行動価値関数（以降、簡単のため Q 関数と呼ぶ）を直接的に推定しなければならない。

価値関数の推定法としてとりえるのは、モンテカルロ法、TD 学習を Q 関数の推定に適用することができる。


## Q関数の制御

環境モデルが既知の場合には、可能なすべての状態と行動の組み合わせについて Q 関数が計算できるので、Q 関数について greedy な方策

![1732573203149](image/3_q-learning/1732573203149.png)

環境モデルが未知の場合、その時点までに観測された行動状態系列にしたがって Q 関数を推定するしかないので、Q 関数について greedy な方策が最適であるとは保証されない
